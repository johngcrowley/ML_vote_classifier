{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde35b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06353831",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "sns.set(style='darkgrid',palette='deep',font_scale=1.1,rc={'figure.figsize':[20,10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428a42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training files\n",
    "survey = pd.read_csv('survey_responses_training.csv')\n",
    "voter_info = pd.read_csv('voter_information_training.csv')\n",
    "voter_hist = pd.read_csv('voting_history_training.csv')\n",
    "\n",
    "#testing files\n",
    "survey_test = pd.read_csv('survey_responses_testing.csv')\n",
    "voter_info_test = pd.read_csv('voter_information_testing.csv')\n",
    "voter_hist_test = pd.read_csv('voting_history_testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b39c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f2f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b88d0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_survey_info(survey,voter_info):\n",
    "    df = pd.merge(survey,voter_info,how='outer',on='myv_van_id')\n",
    "    return df\n",
    "\n",
    "def clean_voter_history_training(voter_hist):\n",
    "    voter_hist['voted'] = np.where(voter_hist['election_date'] == '2018-11-06',1,0)\n",
    "    voted = voter_hist.loc[voter_hist['voted'] == 1]\n",
    "    voter_hist = voter_hist.drop_duplicates(subset='myv_van_id')\n",
    "    notvoted = voter_hist.loc[voter_hist['voted'] == 0]\n",
    "    notvoted = notvoted[notvoted['myv_van_id'].isin(voted['myv_van_id']) == False]\n",
    "    df3 = pd.concat([voted,notvoted])\n",
    "    df3 = df3.drop(columns=['Unnamed: 0','party_id']).set_index('myv_van_id')\n",
    "    return df3\n",
    "\n",
    "def clean_voter_history_testing(voter_hist_test):\n",
    "    voter_hist_test = voter_hist_test.drop_duplicates(subset='myv_van_id')\n",
    "    df3 = voter_hist_test.drop(columns=['party_id']).set_index('myv_van_id')\n",
    "    return df3\n",
    "\n",
    "def feature_engineer_voterhistory(cleaned_voter_hist,voter_hist):\n",
    "    \n",
    "    elecs = len(voter_hist['election_date'].unique())\n",
    "    gb = voter_hist.groupby('myv_van_id')['election_date']\n",
    "    voter_gb_van_id = (gb.count()).apply(lambda x: round(100* x/elecs,2))\n",
    "    \n",
    "    history_gb_elections = pd.DataFrame(voter_gb_van_id).reset_index().rename(columns={'election_date':'% election'})\n",
    "    df2 = pd.merge(history_gb_elections,cleaned_voter_hist,how='inner',on='myv_van_id')\n",
    "    df2 = df2.drop(columns=['election_date'])\n",
    "    df3 = pd.pivot_table(data=df2,index='myv_van_id')\n",
    "#     df3['voted'] = np.where(df3['voted'] > 0,1,0)\n",
    "    return df3\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df['eday'] = '2018-11-06'\n",
    "    df['registration_date'] = pd.to_datetime(df['registration_date']).dt.date\n",
    "    df['eday'] = pd.to_datetime(df['eday']).dt.date\n",
    "\n",
    "\n",
    "    # get days since, normalize by years. note: same day registration = 0\n",
    "    df['vote_since_register'] = (df['eday'] - df['registration_date'])\n",
    "    df['vote_since_register'] = df['vote_since_register'].apply(lambda x: round(int(x.days) / 365,1))\n",
    "    return df\n",
    "\n",
    "def merge(df,df3):\n",
    "    col_renames = {'age_combined':'age',\n",
    "             'gender_combined':'gender',\n",
    "             'ethnicity_combined':'ethnicity',\n",
    "             'state_house_district_latest':'state_house',\n",
    "             'state_senate_district_latest':'state_senate',\n",
    "             'vote_since_register':'yrs_reg',\n",
    "             'us_cong_district_latest':'CD'}\n",
    "    df = df.rename(columns=col_renames)\n",
    "    \n",
    "    col_to_drop = ['datetime_canvassed','master_survey_question_name',\n",
    "                   'contact_type_name','registration_date','van_precinct_name','eday',\n",
    "                   'master_survey_response_name','zip','state_house','state_senate']\n",
    "    df = df.drop(col_to_drop,axis=1)\n",
    "    \n",
    "    training = pd.merge(df3,df,on='myv_van_id',how='inner')\n",
    "    training = training.drop_duplicates(subset='myv_van_id')\n",
    "    training = training[training['gender'].isin(['M','F'])]\n",
    "    return training\n",
    "\n",
    "def encode_X_y(data):\n",
    "    data_encoded = pd.get_dummies(data,columns=['CD','gender','ethnicity']).set_index('myv_van_id')\n",
    "    data_encoded = data_encoded.drop(columns=['CD_26'])\n",
    "    y = data_encoded.voted.dropna(how='all')\n",
    "    X = data_encoded.drop(columns='voted').dropna(how='all')\n",
    "    return X,y\n",
    "\n",
    "def encode_test(data):\n",
    "    XT = pd.get_dummies(data,columns=['CD','gender','ethnicity']).set_index('myv_van_id')\n",
    "    return XT\n",
    "\n",
    "def train_test_clf(X,y,XT):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=47)\n",
    "    \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = min_max_scaler.transform(X_test)\n",
    "    \n",
    "    clf = GradientBoostingClassifier(learning_rate=.01,max_depth=2, n_estimators=1000, random_state=47)\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    y_pred_prob = clf.predict_proba(X_test_scaled)[:,1]\n",
    "    auc = roc_auc_score(y_test,y_pred_prob)\n",
    "    print(f'training auc score is {auc}')\n",
    "    \n",
    "    XT_scaled = min_max_scaler.transform(XT)\n",
    "    y_pred = clf.predict(XT_scaled)\n",
    "    output = pd.DataFrame(XT.index,y_pred).reset_index()\n",
    "    output = output.rename(columns={'index':'Voted'})\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3111c510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training auc score is 0.8792551083941813\n"
     ]
    }
   ],
   "source": [
    "# 1.) Run Training Files thru functions\n",
    "df = merge_survey_info(survey,voter_info)\n",
    "cleaned_voter_hist = clean_voter_history_training(voter_hist)\n",
    "df3 = feature_engineer_voterhistory(cleaned_voter_hist,voter_hist)\n",
    "df = feature_engineering(df)\n",
    "training = merge(df,df3)\n",
    "X = encode_X_y(training)[0]\n",
    "y = encode_X_y(training)[1]\n",
    "\n",
    "# 2.) Run Test Files thru functions\n",
    "df_test = merge_survey_info(survey_test,voter_info_test)\n",
    "cleaned_voter_hist_test = clean_voter_history_testing(voter_hist_test)\n",
    "df3_test = feature_engineer_voterhistory(cleaned_voter_hist_test,voter_hist_test)\n",
    "df_test = feature_engineering(df_test)\n",
    "testing = merge(df_test,df3_test)\n",
    "XT = encode_test(testing)\n",
    "\n",
    "# 3.) Run Through Classifier\n",
    "output = train_test_clf(X,y,XT)\n",
    "output = output.to_csv('part_two_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f7123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38ad12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec54b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9de127d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af7a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93039b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125d4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ea0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d0738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa3380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f152f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1cb1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb1b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b6525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb2005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26202fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680fe37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860df2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a703c92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeaff03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4da7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da7d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d404f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d01c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85daab55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a446d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727c931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
